---
title: "02-exercices-regressions-lineraires"
format: html
toc: TRUE
code-fold: FALSE
---

# Exercice 1 : Notes et présence en cours

Données : Dataframe `attend` du package `wooldridge`.

Objectif : Estimer l'effet de la présence en cours sur la réussite à un examen.

## Question 1

*Importer les données et découvrir les variables. Quelles sont les potentielles variables endogènes pour répondre à notre objectif ? Quelle serait la principale variable exogène ?*

## Question 2

*Quel est l'effet attendu de la présence scolaire sur le résultat à l'examen ?*

## Question 3

*Représenter graphiquement la relation entre la réussite et la présence en cours. Quelle est la corrélation entre les deux variables ?*

## Question 4

*Estimer la régression linéaire simple entre la réussite et à la présence en classe. Quel est l'effet estimé de la présence sur la réussite ? Cet effet est-il significatif ? Qu'en est-il de la constante ?*

## Question 5

*Les hypothèses de l'estimation par MCO sont-elles respectées ? Que faut-il en conclure pour notre estimation ?*

## Question 6

*Pourquoi pourrait-il être intéressant d'ajouter l'assiduité dans la remise des devoirs à la régression ? Et pour les anciennes notes à l'université ? Et pour les résultats du test d'entrée à l'université (ACT) ? Quelles sont les relations à attendre avec la réussite à l'examen ?*

## Question 7

Estimer cette régression linéaire, interpréter les coefficients et tester les hypothèses des estimateurs MCO. Que peut-on en conclure ?

## Question 8

*L'impact de la présence est-il le même pour un freshman que pour un autre élève ?* Le modèle au global est-il le même ?

## Exercice2 : Estimation de la valeur d'une maison

Données : `hprice2` du package `wooldridge`.

*Vous travailler pour une agence immobilière qui vous demande d'analyser ses données afin d'expliquer rationnellement les prix de vente des maisons actuellement à la vente. Votre agence souhaite savoir si d'une part la criminalité d'un quartier joue sur le prix du bien immobilier. elle souhaite d'autre part avoir le modèle qui explique le plus possible le prix des maisons (prévoyez des preuves que ce modèle est meilleur que les autres) afin que vous puissiez trouver les maisons qui sont les plus sous-évaluées et qui pourraient ainsi être achetées puis revendues plus cher par l'agence.*

## Exercices 3 : Comprendre le code donné

*Vous travaillez dans un* laboratoire de recherche. Un de vos collègue vous demande de l'aider à comprendre et interpréter le travail d'un stagaire qui n'a pas laissé d'indications sur ce qu'il a fait. Lisez le code suivant, commenter ce qui y est fait et interprétez les résultats. Quelle politique publique pourriez-vous recommander sur la base de ces résultats ?

```{r}
source(here::here("02-codes", "utils", "setup.R"))

data("bwght")

df <- 
  bwght |> 
  tibble() |> 
  select(bwght, faminc, fatheduc, motheduc, cigs, male, white) |>
  mutate(bwght = bwght * 0.0283495) |> 
  drop_na()
```

```{r}
ggplot(df, aes(x = cigs, y = bwght)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", color = "red") 
```

```{r}
model_1 <- lm(bwght ~ cigs + faminc + fatheduc + motheduc + male + white, data = df)
summary(model_1)
```

```{r}
shapiro.test(residuals(model_1))
bptest(model_1)
check_collinearity(model_1)
```

```{r}
coeftest(model_1, vcov = hccm(model_1, type = "hc0"))
```

```{r}
linearHypothesis(
  model_1, 
  c("fatheduc = 0", "motheduc = 0"), 
  vcov = hccm(model_1, type = "hc0")
)

linearHypothesis(
  model_1, 
  c("fatheduc = 0", "motheduc = 0", "faminc = 0"), 
  vcov = hccm(model_1, type = "hc0")
)
```

```{r}
df |> 
  select(faminc, fatheduc, motheduc) |> 
  cor()
```

```{r}
model_2 <- lm(bwght ~ cigs + log(faminc) + male + white, data = df)
coeftest(model_2, vcov = hccm(model_2, type = "hc0"))
```

```{r}
model_3 <- lm(bwght ~ cigs + motheduc + male + white, data = df)
coeftest(model_3, vcov = hccm(model_3, type = "hc0"))
```

```{r}
model_4 <- lm(bwght ~ cigs  + male + white, data = df)
summary(model_4)
```

```{r}
model_5 <- lm(bwght ~ cigs*white  + male + white, data = df)
summary(model_5)
```

```{r}
linearHypothesis(
  model_5, 
  c("cigs = 0", "cigs:white = 0"),
  vcov = hccm(model_5, type = "hc0")
)
```

```{r}
coeftest(model_5, vcov = hccm(model_5, type = "hc0"))
```

```{r}
list_exported_models <-
  ls(pattern = "^model_*") |>
  mget() |>
  set_names(ls(pattern = "^model_*"))
```

```{r}
modelsummary::modelsummary(
  list_exported_models, 
  stars = TRUE,
  gof_map = c("nobs", "adj.r.squared", "aic")
  ) 
```

```{r}
cm <- c("cigs", "cigs:white", "faminc", "log(faminc)", "white", "male", "motheduc",
        "fatheduc")

modelplot(
  list_exported_models, 
  coef_omit = 'Interc', 
  coef_map = cm, 
  vcov = \(x) hccm(x, type = "hc0")
  ) +
geom_vline(xintercept = 0, color = "black", linewidth = 1.2)
```
